## Hi there ðŸ‘‹

I am SmiteshðŸ‘‹, I am a software engineer with extensive experience in developing and optimizing APIs using Node.js, ExpressJS, 
and PostgreSQL. I have experience in building scalable data solutions and ETL pipelines using SQL and 
Informatica PowerCenter. Currently, I am working with Adaptempy
## About me 

- ðŸ”­ Iâ€™m currently working with Adaptemy on develoving adaptive learning solutions.
- ðŸ“« How to reach me: [Email](smitesh22@gmail.com) / [Linkedin](https://www.linkedin.com/in/smitesh-patil/).


![](https://komarev.com/ghpvc/?username=smitesh22&color=blueviolet)

# General Idea on my pinned projects
## 1. Ledgefast  :
â€¢	Developing Ledgefast, an automated solution for managing invoices, bills, and receipts by utilizing LLMs in the backend to efficiently convert them into Excel documents.
â€¢	Built the frontend with Vue.js, deployed on AWS S3 with static web hosting, and served via CloudFront for optimized content delivery.
â€¢	Developed the backend in TypeScript, deployed as a serverless function on AWS Lambda, exposed through API Gateway, with PostgreSQL on AWS RDS as the database
â€¢	Designed and implemented a deployment pipeline using Terraform to define and manage cloud infrastructure, while leveraging GitHub Actions to automate deployments based on Git branch rules.
* Backend API is repo named : NarathMuni
* FrontEnd repo is name : Billeasr //TODO: rename to Ledgefast

## 2. Unsupervised-Machine-Learning-For-Solar-Site-Selection  :
### Tech Stack : [Python, QGIS, PyTorch, Numpy, Pandas, Searborn, Spacy, LaTEX, GeoPandas,API services for data]

- Utilized geospatial data to select optimal sites for solar energy projects, leveraging advanced deep learning technique.
- Analysed Geological Information Systems (GIS) data and developed a machine learning pipeline that involved preprocessing GIS data from multiple web databases, modeling the data, and staging it for input into a deep learning model.
- Developed a multi-input Auto-Encoder to learn representations from geospatial data and applied various clustering algorithms to cluster optimal solar locations.

## 2.  daft.ie_dataengineering_and_analysis
### Tech Stack: [Python, Apache Airflow, Alchemy for Sql, Docker, Airflow Scheduler]

- Orchestrated a data pipeline using Apache Airflow to ingest data from Daft.ie.
- Implemented an ELT process deployed on the Airflow web server, where the ingested data was stored on an AWS S3 bucket and transformed before being loaded into a Snowflake database, serving as the data lake.
- Created a star schema in the data transformation phase by normalising the input data, which was subsequently utilized for data visualization and exploratory data analysis (EDA) in Tableau.
- Automated the process by utilizing the Airflow Scheduler to monitor the AWS bucket for changes and containerized the project using Docker for easy deployment.

## 3.  Masters-Assignment-Data
### Tech Stack: [Python, R, PyTorch, Numpy, Pandas, Searborn, Sci-kit learn, LaTEX]

- Repository for my college work during my Master's at University of Galway.

  
